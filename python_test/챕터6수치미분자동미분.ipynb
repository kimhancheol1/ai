{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수치미분 자동미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수치미분\n",
    "    수치미분은 함수의 미분값을 근사적으로 계산하는 방법입니다. 가장 일반적인 방법은 차분 방법 (finite difference method)입니다. 차분 방법은 함수의 작은 변화를 이용하여 미분값을 계산합니다.\n",
    "\n",
    "        전진 차분 (Forward Difference)\n",
    "        전진 차분은 다음과 같이 계산됩니다:\n",
    "\n",
    "        [ f'(x) \\approx \\frac{f(x + h) - f(x)}{h} ]\n",
    "\n",
    "        여기서 ( h )는 매우 작은 값입니다.\n",
    "\n",
    "        후진 차분 (Backward Difference)\n",
    "        후진 차분은 다음과 같습니다:\n",
    "\n",
    "        [ f'(x) \\approx \\frac{f(x) - f(x - h)}{h} ]\n",
    "\n",
    "        중앙 차분 (Central Difference)\n",
    "        중앙 차분은 전진 차분과 후진 차분의 평균을 사용하여 더 정확한 값을 제공합니다:\n",
    "\n",
    "        [ f'(x) \\approx \\frac{f(x + h) - f(x - h)}{2h} ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.000010000027032\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "def numerical_derivative(f, x, h=1e-5):\n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "x = 2.0\n",
    "print(numerical_derivative(f, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numer_deriv(f, x, h=0.001, method=\"center\"):\n",
    "    \"\"\"\n",
    "    {f(x+h) - f(x)} / h을 수치적으로 계산한다.\n",
    "    f : 미분할 함수로 주어진 위치에서 함숫값 계산을 위해 사용 \n",
    "    x : 미분계수를 구할 변수의 위치로\n",
    "    일변수인 경우 int 또는 float\n",
    "    다변수인 경우 넘파이 어레이 (d,) 벡터 \n",
    "    h : 비율을 구할 작은 구간\n",
    "    \"\"\"\n",
    "    if type(x) in (float, int):\n",
    "        grad=[0,0]\n",
    "        x_ = [x]\n",
    "        var_type = 'scalar'\n",
    "    else:\n",
    "        grad = np.zeros(x.shape)\n",
    "        x_ = x.copy().astype('float32')\n",
    "        var_type = 'vector'\n",
    "\n",
    "    for i, xi in enumerate(x_):\n",
    "        original_value = x_[i]\n",
    "        if method=='forward' :\n",
    "            x_[i] = original_value + h\n",
    "        else :\n",
    "            x_[i] = original_value + (h/2)\n",
    "\n",
    "        if var_type == 'scalar':\n",
    "            gradplus = f(x_[i])\n",
    "        else :\n",
    "            gradplus = f(x_)\n",
    "\n",
    "        if method=='forward' :\n",
    "            x_[i] = original_value\n",
    "        else:\n",
    "            x_[i] = original_value - (h/2)\n",
    "        \n",
    "        if var_type == 'scalar' :\n",
    "            gradminus = f(x_[i])\n",
    "        else :\n",
    "            gradminus = f(x_)\n",
    "\n",
    "        grad[i] = (gradplus - gradminus) / h \n",
    "        x_[i] = original_value\n",
    "\n",
    "    if var_type == 'scalar' : #❽\n",
    "        return grad[0] \n",
    "    else :\n",
    "        return grad\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "직접미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g(x) = 3*x**3 - 5*x + 4\n",
      "g'(x) = 9*x**2 - 5\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "\n",
    "# 변수 x를 정의\n",
    "x = sp.symbols('x')\n",
    "\n",
    "# 함수 g(x) = 3x^3 - 5x + 4 정의\n",
    "g = 3*x**3 - 5*x + 4\n",
    "\n",
    "# 함수 g(x)를 x에 대해 미분\n",
    "g_prime = sp.diff(g, x)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"g(x) = {g}\")\n",
    "print(f\"g'(x) = {g_prime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자동미분\n",
    "\n",
    "- 연쇄법칙을 함수에 반복적으로 적용 미분계수 자동으로 계산하는 방식\n",
    "\n",
    "### 파이토치로 미분하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5488135  0.71518937 0.60276338]\n",
      " [0.54488318 0.4236548  0.64589411]] float64\n",
      "tensor([[0.5488, 0.7152, 0.6028],\n",
      "        [0.5449, 0.4237, 0.6459]], dtype=torch.float64) torch.float64 False\n",
      "tensor([[0.5488, 0.7152, 0.6028],\n",
      "        [0.5449, 0.4237, 0.6459]], dtype=torch.float64) torch.float64 False\n",
      "tensor([[0.5488, 0.7152, 0.6028],\n",
      "        [0.5449, 0.4237, 0.6459]]) torch.float32 False\n",
      "tensor([[0.5488, 0.7152, 0.6028],\n",
      "        [0.5449, 0.4237, 0.6459]], dtype=torch.float64) torch.float64 False\n",
      "[[100.           0.71518937   0.60276338]\n",
      " [  0.54488318   0.4236548    0.64589411]] float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "np.random.seed(0) # ❶\n",
    "x = np.random.rand(6).reshape(2,3) #❷\n",
    "x_tensor = torch.tensor(x) #❸ \n",
    "x_from_numpy = torch.from_numpy(x) \n",
    "x_Tensor = torch.Tensor(x)\n",
    "x_as_Tensor = torch.as_tensor(x)\n",
    "\n",
    "print(x, x.dtype)\n",
    "print(x_tensor, x_tensor.dtype, x_tensor.requires_grad)\n",
    "print(x_from_numpy, x_from_numpy.dtype, x_from_numpy.requires_grad)\n",
    "print(x_Tensor, x_Tensor.dtype, x_Tensor.requires_grad)\n",
    "print(x_as_Tensor, x_as_Tensor.dtype, x_as_Tensor.requires_grad)\n",
    "x[0,0] = 100\n",
    "print(x,x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100.0000,   0.7152,   0.6028],\n",
      "        [  0.5449,   0.4237,   0.6459]], dtype=torch.float64,\n",
      "       requires_grad=True) torch.float64 True\n"
     ]
    }
   ],
   "source": [
    "x_tensor_grad = torch.tensor(x,requires_grad=True)\n",
    "print(x_tensor_grad, x_tensor_grad.dtype, x_tensor_grad.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.77255303, 1.49989128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_xy(x):\n",
    "    return (x[0]*x[0] + 2*x[0])*np.log(x[1])\n",
    "\n",
    "numer_deriv(f_xy, np.array([1, 2]), method=\"center\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.77255299, 1.49989128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_xy  = lambda x : (x[0]**2 + 2*x[0])*np.log(x[1])\n",
    "numer_deriv(f_xy, np.array([1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자동미분\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7726])\n",
      "tensor([1.5000])\n",
      "(tensor([2.7726]), tensor([1.5000]))\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "y = torch.tensor([2.0], requires_grad=True)\n",
    "f_xy = (x**2 + 2*x) * torch.log(y)\n",
    "\n",
    "torch.autograd.backward(f_xy, retain_graph=True)\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "\n",
    "df = torch.autograd.grad(f_xy, (x,y), retain_graph=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], requires_grad=True)\n",
      "tensor([0.], grad_fn=<MulBackward0>)\n",
      "None\n",
      "None\n",
      "<MulBackward0 object at 0x0000021BE30404C0>\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "f = (x**2 + 2*x) * torch.log(x)\n",
    "\n",
    "print(x)\n",
    "print(f)\n",
    "print(x.grad)\n",
    "\n",
    "print(x.grad_fn)\n",
    "print(f.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.autograd.grad사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.backward(f, grad_tensors=torch.tensor([1.]), retain_graph=True)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([3.]),)\n"
     ]
    }
   ],
   "source": [
    "df = torch.autograd.grad(f, x, retain_graph=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7726])\n",
      "tensor([1.5000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "y = torch.tensor([2.0], requires_grad=True)\n",
    "f_xy = (x**2 + 2*x) * torch.log(y)\n",
    "\n",
    "torch.autograd.backward(f_xy, retain_graph=True)\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "\n",
    "df = torch.autograd.grad(f_xy, (x,y), retain_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_xy = x^3+4x*exp(x)\n",
    "x로 미분 y로 직접미분\n",
    "\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "y = torch.tensor([2.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*x 4*y\n",
      "2*x\n",
      "4*y\n",
      "8.0000\n",
      "20.0000\n",
      "6494.0391\n",
      "9990.8294\n",
      "6415.0378\n"
     ]
    }
   ],
   "source": [
    "import sympy  # sympy 라이브러리를 import 합니다. sympy는 기호적 계산을 위한 Python 라이브러리입니다.\n",
    "\n",
    "x = sympy.Symbol('x')  # x를 기호 변수로 선언합니다.\n",
    "y = sympy.Symbol('y')  # y를 기호 변수로 선언합니다.\n",
    "z = sympy.Symbol('z')\n",
    "\n",
    "f_xy_sympy = (x**3 + x*4)*sympy.exp(y)  # 주어진 함수 f(x, y) = (x^3 + 4x)e^y를 정의합니다.\n",
    "f_xyz = (x**3 + x*4)*sympy.exp(y)*sympy.sin(z)\n",
    "df_xy_x = sympy.diff(f_xy_sympy, x)  # f에 대해 x로 편미분합니다.\n",
    "df_xy_y = sympy.diff(f_xy_sympy, y)  # f에 대해 y로 편미분합니다.\n",
    "\n",
    "\n",
    "df_xyz_x = sympy.diff(f_xyz, x)\n",
    "df_xyz_y = sympy.diff(f_xyz, y)\n",
    "df_xyz_z = sympy.diff(f_xyz, z)\n",
    "\n",
    "print(df_xy_x)  # x에 대한 편미분 결과를 출력합니다.\n",
    "print(df_xy_y)  # y에 대한 편미분 결과를 출력합니다.\n",
    "\n",
    "# x=4.0, y=5.0을 대입한 x에 대한 편미분 값과 y에 대한 편미분 값을 계산하여 출력합니다.\n",
    "# .evalf(subs={x:4.0, y:5.0})은 편미분 결과에 x=4.0, y=5.0을 대입하여 수치적으로 평가하는 메소드입니다.\n",
    "# \"{:.4f}\".format()은 계산된 결과를 소수점 넷째 자리까지 포맷팅하여 출력합니다.\n",
    "print(\"{:.4f}\".format(df_xy_x.evalf(subs={x:4.0, y:5.0})))\n",
    "print(\"{:.4f}\".format(df_xy_y.evalf(subs={x:4.0, y:5.0})))\n",
    "\n",
    "print(\"{:.4f}\".format(df_xyz_x.evalf(subs={x:4.0, y:5.0 ,z:1.0})))\n",
    "print(\"{:.4f}\".format(df_xyz_y.evalf(subs={x:4.0, y:5.0 ,z:1.0})))\n",
    "print(\"{:.4f}\".format(df_xyz_z.evalf(subs={x:4.0, y:5.0 ,z:1.0})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numer_deriv(f, x, h=0.001, method=\"center\"):\n",
    "    \"\"\"\n",
    "    {f(x+h) - f(x)} / h을 수치적으로 계산한다.\n",
    "    f : 미분할 함수로 주어진 위치에서 함숫값 계산을 위해 사용 \n",
    "    x : 미분계수를 구할 변수의 위치로\n",
    "    일변수인 경우 int 또는 float\n",
    "    다변수인 경우 넘파이 어레이 (d,) 벡터 \n",
    "    h : 비율을 구할 작은 구간\n",
    "    \"\"\"\n",
    "    if type(x) in (float, int):\n",
    "        grad=[0,0]\n",
    "        x_ = [x]\n",
    "        var_type = 'scalar'\n",
    "    else:\n",
    "        grad = np.zeros(x.shape)\n",
    "        x_ = x.copy().astype('float32')\n",
    "        var_type = 'vector'\n",
    "\n",
    "    for i, xi in enumerate(x_):\n",
    "        original_value = x_[i]\n",
    "        if method=='forward' :\n",
    "            x_[i] = original_value + h\n",
    "        else :\n",
    "            x_[i] = original_value + (h/2)\n",
    "\n",
    "        if var_type == 'scalar':\n",
    "            gradplus = f(x_[i])\n",
    "        else :\n",
    "            gradplus = f(x_)\n",
    "\n",
    "        if method=='forward' :\n",
    "            x_[i] = original_value\n",
    "        else:\n",
    "            x_[i] = original_value - (h/2)\n",
    "        \n",
    "        if var_type == 'scalar' :\n",
    "            gradminus = f(x_[i])\n",
    "        else :\n",
    "            gradminus = f(x_)\n",
    "\n",
    "        grad[i] = (gradplus - gradminus) / h \n",
    "        x_[i] = original_value\n",
    "\n",
    "    if var_type == 'scalar' : #❽\n",
    "        return grad[0] \n",
    "    else :\n",
    "        return grad\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numer_deriv2(f, x, h=0.001, method=\"center\"):\n",
    "    \"\"\"\n",
    "    {f(x+h) - f(x)} / h을 수치적으로 계산한다.\n",
    "    \n",
    "    f      : 미분할 함수로 주어진 위치에서 함수값 계산을 위해 사용\n",
    "    x      : 미분계수를 구할 변수의 위치로 \n",
    "             일변수인 경우 int 또는 float \n",
    "             다변수인 경우 넘파이 어레이 (d,) 벡터\n",
    "    h      : 비율을 구할 작은 구간\n",
    "    \"\"\"\n",
    "    if type(x) in (float, int):    # ---- [1]\n",
    "        grad = [0.0]\n",
    "        x_ = [x]\n",
    "        var_type = 'scalar'\n",
    "    else:\n",
    "        grad = np.zeros(x.shape)    # ---- [2]\n",
    "        x_ = x.copy().astype('float32')\n",
    "        var_type = 'vector'\n",
    "    \n",
    "    for i, xi in enumerate(x_):    # ---- [3]\n",
    "        original_value = x_[i]\n",
    "        \n",
    "        if method == 'forward':    # ---- [4]\n",
    "            x_[i] = original_value + h\n",
    "        else:\n",
    "            x_[i] = original_value + (h / 2)\n",
    "        \n",
    "        if var_type == 'scalar':    # ---- [5]   \n",
    "            gradplus = f(*x_)\n",
    "        else:\n",
    "            gradplus = f(*x_)\n",
    "        \n",
    "        if method == 'forward':    # ---- [6]   \n",
    "            x_[i] = original_value\n",
    "        else:\n",
    "            x_[i] = original_value - (h / 2)\n",
    "        \n",
    "        if var_type == 'scalar':\n",
    "            gradminus = f(*x_)\n",
    "        else:\n",
    "            gradminus = f(*x_)\n",
    "        \n",
    "        grad[i] = (gradplus - gradminus) / h    # ---- [7]\n",
    "    \n",
    "    if var_type == 'scalar':    # ---- [8]\n",
    "        return grad[0]\n",
    "    else:\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient at point (4.0, 5.0, 1.0): [6495.11747766 9991.27508271 6409.91010514]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 심볼 정의\n",
    "x, y, z = sp.symbols('x y z')\n",
    "\n",
    "# 주어진 함수 정의\n",
    "f_sym = (x**3 + 4*x) * sp.exp(y) * sp.sin(z)\n",
    "\n",
    "# sympy 함수를 numpy 함수로 변환\n",
    "f_np = sp.lambdify((x, y, z), f_sym, 'numpy')\n",
    "\n",
    "point = np.array([4.0, 5.0, 1.0])\n",
    "\n",
    "# 수치 미분 계산\n",
    "gradient = numer_deriv2(f_np, point)\n",
    "\n",
    "print(\"Gradient at point (4.0, 5.0, 1.0):\", gradient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6502.8585877  10004.79455543  6411.66329297]\n"
     ]
    }
   ],
   "source": [
    "f = lambda x : (x[0]**3 + x[0]*4)*np.exp(x[1])*np.sin(x[2])\n",
    "\n",
    "#f = lambda x,y,z : (x**3 + x*4)*np.exp(y)*np.sin(z)\n",
    "\n",
    "print(numer_deriv(f, np.array([4,5,1]),h=0.0001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([29914.9727]), tensor([35897.9648]), tensor([-16428.9746]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([3.0], requires_grad=True)\n",
    "y = torch.tensor([7.0], requires_grad=True)\n",
    "z = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "\n",
    "f_xyz =(x**3 + x*3)*torch.exp(y)*torch.sin(z)\n",
    "#torch.autograd.backward(f_xyz, retain_graph=True)\n",
    "\n",
    "df = torch.autograd.grad(f_xyz, (x,y,z), retain_graph=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3*x**2 + 4)*exp(y)\n",
      "(x**3 + 4*x)*exp(y)\n",
      "7717.4843\n",
      "11873.0527\n",
      "6494.0391\n",
      "9990.8294\n",
      "6415.0378\n"
     ]
    }
   ],
   "source": [
    "import sympy  # sympy 라이브러리를 import 합니다. sympy는 기호적 계산을 위한 Python 라이브러리입니다.\n",
    "\n",
    "x = sympy.Symbol('x')  # x를 기호 변수로 선언합니다.\n",
    "y = sympy.Symbol('y')  # y를 기호 변수로 선언합니다.\n",
    "z = sympy.Symbol('z')\n",
    "f_xy_sympy = (x**3 + x*4)*sympy.exp(y)  # 주어진 함수 f(x, y) = (x^3 + 4x)e^y를 정의합니다.\n",
    "f_xyz = (x**3 + x*4)*sympy.exp(y)*sympy.sin(z)\n",
    "df_xy_x = sympy.diff(f_xy_sympy, x)  # f에 대해 x로 편미분합니다.\n",
    "df_xy_y = sympy.diff(f_xy_sympy, y)  # f에 대해 y로 편미분합니다.\n",
    "\n",
    "\n",
    "df_xyz_x = sympy.diff(f_xyz, x)\n",
    "df_xyz_y = sympy.diff(f_xyz, y)\n",
    "df_xyz_z = sympy.diff(f_xyz, z)\n",
    "\n",
    "print(df_xy_x)  # x에 대한 편미분 결과를 출력합니다.\n",
    "print(df_xy_y)  # y에 대한 편미분 결과를 출력합니다.\n",
    "\n",
    "# x=4.0, y=5.0을 대입한 x에 대한 편미분 값과 y에 대한 편미분 값을 계산하여 출력합니다.\n",
    "# .evalf(subs={x:4.0, y:5.0})은 편미분 결과에 x=4.0, y=5.0을 대입하여 수치적으로 평가하는 메소드입니다.\n",
    "# \"{:.4f}\".format()은 계산된 결과를 소수점 넷째 자리까지 포맷팅하여 출력합니다.\n",
    "print(\"{:.4f}\".format(df_xy_x.evalf(subs={x:4.0, y:5.0})))\n",
    "print(\"{:.4f}\".format(df_xy_y.evalf(subs={x:4.0, y:5.0})))\n",
    "\n",
    "print(\"{:.4f}\".format(df_xyz_x.evalf(subs={x:4.0, y:5.0 ,z:1.0})))\n",
    "print(\"{:.4f}\".format(df_xyz_y.evalf(subs={x:4.0, y:5.0 ,z:1.0})))\n",
    "print(\"{:.4f}\".format(df_xyz_z.evalf(subs={x:4.0, y:5.0 ,z:1.0})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
